{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convex Optimization\n",
    "* Ref: https://people.eecs.berkeley.edu/~jordan/courses/294-fall09/lectures/optimization/slides.pdf\n",
    "* Find the **function parameters** for a given function set that give the **minimum function output**, subject to constrains\n",
    "* e.g. minimize $f_{0}(x)$ given $f_{i}(x)$ <= 0 and $h_{j}(x)$ == 0\n",
    "* **Most machine learning problems are optimization problems**\n",
    "* e.g. Linear Regression : $\\displaystyle{\\min_{w} ||Xw - y||^2}$\n",
    "* e.g Classification (log regression or SVM): $\\displaystyle{\\min_{w} \\sum_{i=1}^n log(1+(exp^-y_{i}x^T_{i}w))}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-Convex Approaches\n",
    "* Maximum Likelihood Method: $\\displaystyle{\\max_{\\theta}\\sum_{i=1}^n log p_{\\theta}x_{i}}$  `Break out`\n",
    "* Collaborative Filtering: $\\displaystyle{\\min_{w} \\sum_{i < j} log(1 + (exp(w^T x_{i} - w^T x_{j}}))$ `i < j indicates strictly increasing order here, need to understand what that i and j are, Break Out`\n",
    "* k-means; $\\displaystyle{\\min_{\\mu_{1}, ..., \\mu_{k}} J(\\mu) = \\sum_{j=1}^k \\sum_{i\\in C}||{x_{i} - \\mu_{i}||^2}}$ `Minimize squared distance for all points i in cluster k, the set of C points, Break Out`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why Doesn't Non-Convex Algo Work on Convex Sets?\n",
    "* 1. Local Minima of $\\displaystyle{f_{0}}$!\n",
    "* 2. Non-convex approaches can't handle constraints! - a typical surface sample $\\displaystyle{h_{x} = sin(2{\\pi}x) = 0}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convex Set\n",
    "* A Euclidean subspace bounded (but not defined) by a set of points whom the lines between are contained within the bounds of the subspace\n",
    "* Formally: The set $\\displaystyle{C \\subseteq \\mathbb{R}^n}$ is convex if for $\\displaystyle{x, y \\in C}$ and any $\\displaystyle{\\alpha \\in [0,1]}$, $\\displaystyle{\\alpha x + (1 - \\alpha)y \\in C}$\n",
    "* Obviously the real numbers are a convex set\n",
    "* The positive quadrants of the plane are a convex set\n",
    "* The intersection of two convex sets is a convex set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convex Functions\n",
    "* Functions whose range is a convex set\n",
    "* The _epigraph_ of a function $\\displaystyle{f}$ is the region bounded by the convex domain of $\\displaystyle{f}$\n",
    "* The geometric interpretation is that the graph of $\\displaystyle{f}$ is bounded below everywhere by anyone of its tangents.\n",
    "* In vector calculus, the gradient of a scalar field y in the space Rn (whose independent coordinates are the components of x) is the transpose of the derivative of a scalar by a vector.\n",
    "* Example: Support Vector Machine Loss $\\displaystyle{f(w) =[1 - y_{i}x_{i}^Tw]_{+}}$ `feat vector * observation vector * weights`\n",
    "* Example: Binary Logistic Loss: $\\displaystyle{f(w) = log(1 + exp(-y_{i}x_{i}^Tw))}$ `Same product! Just difference vs. sum`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convex Optimization Problems\n",
    "* An optimization problem is convex iff:\n",
    "1. Objective function is convex\n",
    "2. Equality constraints are affine - makes sense, have to be able to tangent the min of convex objective\n",
    "3. Inequality constrains are convex - makes sense, have to be able to bound the function space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nice Properties of Convex Optimization Problems\n",
    "* A local minima of a convex problem is always the global minima because $\\displaystyle{ \\Delta f(x) = 0}$ (derivative test )is a unique solution when above properties are satisfied"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lagrange Duality\n",
    "\n",
    "### Goals of Lagrange Duality\n",
    "1. Certificate of optimality for a problem i.e. _the duality gap_ `TODO fill in more on duality gap and primal/dual here`\n",
    "2. Remove constraints from problem\n",
    "3. Reformulate problem\n",
    "\n",
    "### Formulation\n",
    "* Starting with the convex problem minimize $f_{0}(x)$ given $f_{i}(x)$ <= 0, $\\displaystyle{i = \\{1...k\\}}$ and $h_{j}(x)$ == 0, $\\displaystyle{j = \\{1...l\\}}$\n",
    "* The *Langrangian Form*: $\\displaystyle{\\mathcal{L(x, \\lambda, \\nu)} = f_{0}(x) + \\sum_{i=1}^k \\lambda_{i}f_{i}(x) + \\sum_{j=1}^l v_{j}h_{j}(x)}$ `Explicit solution summing Lagrangian multipliers on constraints`\n",
    "\n",
    "\n",
    "* The *Dual Form*: $\\displaystyle{g(\\lambda, \\nu) = \\inf_{x} \\mathcal{L(x, \\lambda, \\nu)} = \\inf_{x}\\{f_{0}(x) + \\sum_{i=1}^k \\lambda_{i}f_{i}(x) + \\sum_{j=1}^l v_{j}h_{j}(x)\\}}$\n",
    "\n",
    "* The Dual Form converts a _minimization_ problem to a _maximization_ one: $\\displaystyle{\\max_{\\lambda \\geq 0, \\nu[\\inf_{x} \\mathcal{L(x, \\lambda, \\nu)]}}}$\n",
    "\n",
    "* Why this works: \n",
    "\n",
    "* If $\\displaystyle{\\lambda \\geq 0}$, then $\\displaystyle{g(\\lambda, \\nu) \\leq f_{0}(x)}$ `dual form always less than or equal to the minimization`\n",
    "\n",
    "* In ordered set version: $\\displaystyle{\\sup_{\\lambda \\geq 0, \\nu} g(\\lambda, \\nu) = f_{0}(x^*)}$\n",
    "\n",
    "* Thus _Duality is a Linear Approximation_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Duality Gap\n",
    "\n",
    "* TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization Algorithms\n",
    "\n",
    "* Gradient Descent\n",
    "* Newton's Method\n",
    "* Logarithmic Barrier Method\n",
    "* Subgradient Descent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent\n",
    "* $\\displaystyle{\\min_{x}f(x)}$ `That's it`\n",
    "* Iterative solution: $\\displaystyle{x_{t+1} = x_{t} - \\eta_{t} \\nabla f(x_{t})}$ where $\\displaystyle{\\eta_{t}}$ is the step size to descend with - `move the negative of the gradient in vector space`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Newton's Method\n",
    "* Second order approximation (i.e. Taylor Series to 2nd-order) to approximate function\n",
    "* $\\displaystyle{f(x + \\Delta x) \\approx f(x) + \\nabla f(x)^T \\Delta x + 1/2 \\Delta x^T \\nabla ^2 f(x) \\Delta x}$ `function + first gradient + second gradient`\n",
    "* Choosing $\\displaystyle{\\Delta x}$ == step size in gradient descent\n",
    "* $\\displaystyle{\\Delta x = -[\\nabla ^2 f(x)]^{-1} \\nabla f(x)}$\n",
    "* So descent direction is: $\\displaystyle{\\nabla f(x)^T \\Delta x = - \\nabla f(x)^T -[\\nabla ^2 f(x)]^{-1} \\nabla f(x) < 0}$ `i.e. a second order gradient descent`\n",
    "* Takeaway: Newton's often converges faster, but performs poorly for inequality constrains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logarithmic Barrier Methods\n",
    "* A logarithmic barrier method approaches infinity as point approaches the optimal boundary\n",
    "* $\\displaystyle{\\min_{x} f_{0}x s.t. f_{i}(x) \\leq 0, i = \\{1 ... k\\}}$\n",
    "* Equivalent to $\\displaystyle{\\min_{x} f_{0}x + \\sum_{i=1}^k \\mathrm{I}\\_(f_{i}(x)}$ `where I is barrier function`\n",
    "* Approximate $\\displaystyle{\\mathrm{I}\\_(u) \\approx -t log (-u)}$ for a small t-value where u is f(x)\n",
    "* Finally becomes $\\displaystyle{\\min_{x} f_{0}(x) - t \\sum_{i=1}^k log(-f_{i}(x))}$ `the combo of -t and -f(x) make the log approach infinity`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subgradient Descent\n",
    "* The absolute simplest algorithm for optimization: $\\displaystyle{\\min_{x} f(x)}$\n",
    "* Just iterate on: $\\displaystyle{x_{t+1} = x{t} - \\eta_{t} g_{t}}$ where $\\displaystyle{\\eta_{t}}$ is stepsize and $\\displaystyle{g_{t}}$ is the derivative of any feature in $\\displaystyle{f(x_{t})}$ `Just pick one feature's direction to move in`\n",
    "* Useful because it doesn't require the full space to be differentiable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
